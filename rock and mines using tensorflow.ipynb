{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read and encode the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():   \n",
    "    ds = pd.read_csv(r\"C:\\Users\\Lenovo\\jupyter project\\rock and mines\\rock and mines.csv\")\n",
    "    ds.head(5)\n",
    "    X = ds[ds.columns[0:60]].values\n",
    "    y = ds[ds.columns[60]]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the encoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the encoded dataset and Shuffle the dataset to mix up the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n"
     ]
    }
   ],
   "source": [
    "X, Y = read_data()\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0257, 0.0447, 0.0388, ..., 0.0199, 0.0255, 0.018 ],\n",
       "       [0.0067, 0.0096, 0.0024, ..., 0.0034, 0.0051, 0.0031],\n",
       "       [0.0129, 0.0141, 0.0309, ..., 0.0017, 0.0024, 0.0029],\n",
       "       ...,\n",
       "       [0.0216, 0.0215, 0.0273, ..., 0.0024, 0.0009, 0.0017],\n",
       "       [0.0216, 0.0124, 0.0174, ..., 0.0018, 0.0006, 0.0023],\n",
       "       [0.0162, 0.0253, 0.0262, ..., 0.01  , 0.0048, 0.0019]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.024 , 0.0218, 0.0324, ..., 0.0019, 0.0066, 0.0023],\n",
       "       [0.0352, 0.0116, 0.0191, ..., 0.0015, 0.0073, 0.0067],\n",
       "       [0.013 , 0.012 , 0.0436, ..., 0.0009, 0.0033, 0.0026],\n",
       "       ...,\n",
       "       [0.0664, 0.0575, 0.0842, ..., 0.0162, 0.0109, 0.0079],\n",
       "       [0.0068, 0.0232, 0.0513, ..., 0.0052, 0.0194, 0.0105],\n",
       "       [0.0274, 0.0242, 0.0621, ..., 0.0161, 0.022 , 0.0173]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters and variables to we=ork with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 60\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 2\n",
    "model_path = (r\"C:\\Users\\Lenovo\\jupyter project\\rock and mines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the number of hidden layers and the number of neurons for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "x= tf.placeholder(tf.float32,[None, n_dim])\n",
    "y_ = tf.placeholder(tf.float32,[None, n_class])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activations\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['W1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with sigmoid activations\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['W2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    # Hidden layer with sigmoid activations\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['W3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    # Hidden layer with RELU activations\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['W4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    # Output layer with linear activations\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the weights and the biases for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'W1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'W2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'W3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'W4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "    }\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost function and Gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-a7431524031e>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the cost and accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.71428573\n",
      "epoch:  0  -  cost:  0.33377898  - MSE:  3.912116363885515 - Train Accuracy:  0.875\n",
      "Accuracy:  0.71428573\n",
      "epoch:  1  -  cost:  0.366099  - MSE:  3.323525393691175 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.6507937\n",
      "epoch:  2  -  cost:  0.620581  - MSE:  6.8815786274922885 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.42857143\n",
      "epoch:  3  -  cost:  1.0904582  - MSE:  3.2341393542387733 - Train Accuracy:  0.4861111\n",
      "Accuracy:  0.44444445\n",
      "epoch:  4  -  cost:  0.7181383  - MSE:  0.8656827492769347 - Train Accuracy:  0.49305555\n",
      "Accuracy:  0.6507937\n",
      "epoch:  5  -  cost:  0.61575085  - MSE:  1.4957941515062163 - Train Accuracy:  0.6875\n",
      "Accuracy:  0.71428573\n",
      "epoch:  6  -  cost:  0.59762204  - MSE:  1.812652638359105 - Train Accuracy:  0.7152778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  7  -  cost:  0.5807367  - MSE:  1.658613951072941 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.6825397\n",
      "epoch:  8  -  cost:  0.5628087  - MSE:  1.6173565895724087 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.73015875\n",
      "epoch:  9  -  cost:  0.5456364  - MSE:  1.572428059818329 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.73015875\n",
      "epoch:  10  -  cost:  0.52891797  - MSE:  1.5766344611217051 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.71428573\n",
      "epoch:  11  -  cost:  0.512179  - MSE:  1.6618325203352218 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.74603176\n",
      "epoch:  12  -  cost:  0.49782312  - MSE:  1.7044057128358594 - Train Accuracy:  0.7916667\n",
      "Accuracy:  0.74603176\n",
      "epoch:  13  -  cost:  0.4858688  - MSE:  1.8514277522425593 - Train Accuracy:  0.7916667\n",
      "Accuracy:  0.7619048\n",
      "epoch:  14  -  cost:  0.47598642  - MSE:  1.777493198655835 - Train Accuracy:  0.8194444\n",
      "Accuracy:  0.71428573\n",
      "epoch:  15  -  cost:  0.4677784  - MSE:  2.0776103232700076 - Train Accuracy:  0.7916667\n",
      "Accuracy:  0.71428573\n",
      "epoch:  16  -  cost:  0.47073248  - MSE:  1.7194168916582075 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.6666667\n",
      "epoch:  17  -  cost:  0.5296784  - MSE:  3.3717063407507384 - Train Accuracy:  0.7013889\n",
      "Accuracy:  0.50793654\n",
      "epoch:  18  -  cost:  0.7158549  - MSE:  1.7674747390463739 - Train Accuracy:  0.5833333\n",
      "Accuracy:  0.6984127\n",
      "epoch:  19  -  cost:  0.45946324  - MSE:  2.1048671481041406 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.6666667\n",
      "epoch:  20  -  cost:  0.47940192  - MSE:  1.6600456718861145 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.61904764\n",
      "epoch:  21  -  cost:  0.60173494  - MSE:  4.589458501105159 - Train Accuracy:  0.6388889\n",
      "Accuracy:  0.4920635\n",
      "epoch:  22  -  cost:  0.75718725  - MSE:  2.2643954491322282 - Train Accuracy:  0.5694444\n",
      "Accuracy:  0.52380955\n",
      "epoch:  23  -  cost:  0.6167062  - MSE:  1.8755381044169197 - Train Accuracy:  0.625\n",
      "Accuracy:  0.6825397\n",
      "epoch:  24  -  cost:  0.43295425  - MSE:  2.050613183048781 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.74603176\n",
      "epoch:  25  -  cost:  0.4133582  - MSE:  2.570237224425014 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.6666667\n",
      "epoch:  26  -  cost:  0.40874985  - MSE:  2.448185344973328 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  27  -  cost:  0.4549702  - MSE:  3.8276100892466554 - Train Accuracy:  0.75\n",
      "Accuracy:  0.50793654\n",
      "epoch:  28  -  cost:  0.6669124  - MSE:  3.8602322663708826 - Train Accuracy:  0.6041667\n",
      "Accuracy:  0.6666667\n",
      "epoch:  29  -  cost:  0.5168817  - MSE:  3.036626033286149 - Train Accuracy:  0.7013889\n",
      "Accuracy:  0.52380955\n",
      "epoch:  30  -  cost:  0.6406552  - MSE:  2.1972535549521712 - Train Accuracy:  0.5972222\n",
      "Accuracy:  0.52380955\n",
      "epoch:  31  -  cost:  0.5320515  - MSE:  1.9247594398474404 - Train Accuracy:  0.7013889\n",
      "Accuracy:  0.6984127\n",
      "epoch:  32  -  cost:  0.42397925  - MSE:  2.4393618471144634 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.53968257\n",
      "epoch:  33  -  cost:  0.50834626  - MSE:  2.5170595017020516 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.71428573\n",
      "epoch:  34  -  cost:  0.45335352  - MSE:  2.822333774343747 - Train Accuracy:  0.75\n",
      "Accuracy:  0.52380955\n",
      "epoch:  35  -  cost:  0.5836097  - MSE:  3.2068536509205456 - Train Accuracy:  0.6180556\n",
      "Accuracy:  0.6825397\n",
      "epoch:  36  -  cost:  0.40516135  - MSE:  2.562549702478108 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.73015875\n",
      "epoch:  37  -  cost:  0.34254414  - MSE:  3.0193266891653257 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.73015875\n",
      "epoch:  38  -  cost:  0.36603472  - MSE:  4.088720167834982 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.63492066\n",
      "epoch:  39  -  cost:  0.6027937  - MSE:  3.9996478104934305 - Train Accuracy:  0.6736111\n",
      "Accuracy:  0.4920635\n",
      "epoch:  40  -  cost:  0.8102915  - MSE:  5.3981225701912985 - Train Accuracy:  0.5555556\n",
      "Accuracy:  0.46031746\n",
      "epoch:  41  -  cost:  0.7060564  - MSE:  1.9507687764508186 - Train Accuracy:  0.5486111\n",
      "Accuracy:  0.52380955\n",
      "epoch:  42  -  cost:  0.5402098  - MSE:  1.523535881219209 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.6666667\n",
      "epoch:  43  -  cost:  0.49067625  - MSE:  2.1519662123289827 - Train Accuracy:  0.75\n",
      "Accuracy:  0.50793654\n",
      "epoch:  44  -  cost:  0.5373458  - MSE:  2.0022062315216367 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.6825397\n",
      "epoch:  45  -  cost:  0.477039  - MSE:  2.3350971520220427 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.50793654\n",
      "epoch:  46  -  cost:  0.5716607  - MSE:  2.315573828723703 - Train Accuracy:  0.6666667\n",
      "Accuracy:  0.6507937\n",
      "epoch:  47  -  cost:  0.40065375  - MSE:  2.3259173661493797 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.71428573\n",
      "epoch:  48  -  cost:  0.380084  - MSE:  2.4776928499623803 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.71428573\n",
      "epoch:  49  -  cost:  0.36601523  - MSE:  2.8409468980160777 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.73015875\n",
      "epoch:  50  -  cost:  0.35797882  - MSE:  2.8514103810702967 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.6984127\n",
      "epoch:  51  -  cost:  0.36358377  - MSE:  3.4324063716410333 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.6666667\n",
      "epoch:  52  -  cost:  0.4720972  - MSE:  3.9924796736089356 - Train Accuracy:  0.7083333\n",
      "Accuracy:  0.5555556\n",
      "epoch:  53  -  cost:  0.7149565  - MSE:  5.000611125538267 - Train Accuracy:  0.5902778\n",
      "Accuracy:  0.5555556\n",
      "epoch:  54  -  cost:  0.43450806  - MSE:  2.806671243237355 - Train Accuracy:  0.7986111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  55  -  cost:  0.36184928  - MSE:  3.515849290684571 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.73015875\n",
      "epoch:  56  -  cost:  0.367477  - MSE:  2.874667446316586 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.73015875\n",
      "epoch:  57  -  cost:  0.40574148  - MSE:  4.125214879790345 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.53968257\n",
      "epoch:  58  -  cost:  0.5795063  - MSE:  3.7567555853322023 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.6825397\n",
      "epoch:  59  -  cost:  0.3348289  - MSE:  4.346031968181658 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  60  -  cost:  0.3172851  - MSE:  3.2951409122610853 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.73015875\n",
      "epoch:  61  -  cost:  0.3296904  - MSE:  4.144868992116608 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.61904764\n",
      "epoch:  62  -  cost:  0.46504307  - MSE:  4.582972653692446 - Train Accuracy:  0.7708333\n",
      "Accuracy:  0.63492066\n",
      "epoch:  63  -  cost:  0.54803437  - MSE:  6.00954237256752 - Train Accuracy:  0.7291667\n",
      "Accuracy:  0.47619048\n",
      "epoch:  64  -  cost:  0.80407536  - MSE:  3.9522087281862315 - Train Accuracy:  0.5486111\n",
      "Accuracy:  0.5555556\n",
      "epoch:  65  -  cost:  0.6393625  - MSE:  1.8979607262946112 - Train Accuracy:  0.6111111\n",
      "Accuracy:  0.50793654\n",
      "epoch:  66  -  cost:  0.5575852  - MSE:  2.200261179975832 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.6666667\n",
      "epoch:  67  -  cost:  0.41461438  - MSE:  2.90588160167971 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  68  -  cost:  0.35211456  - MSE:  4.585992151484122 - Train Accuracy:  0.875\n",
      "Accuracy:  0.7619048\n",
      "epoch:  69  -  cost:  0.31306648  - MSE:  4.235215430934236 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.71428573\n",
      "epoch:  70  -  cost:  0.29659906  - MSE:  5.476919636280456 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.71428573\n",
      "epoch:  71  -  cost:  0.33411968  - MSE:  5.587618406808167 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.6666667\n",
      "epoch:  72  -  cost:  0.45188352  - MSE:  7.176953693873987 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.52380955\n",
      "epoch:  73  -  cost:  0.7096781  - MSE:  4.568184356779422 - Train Accuracy:  0.5833333\n",
      "Accuracy:  0.53968257\n",
      "epoch:  74  -  cost:  0.5065394  - MSE:  2.179569978881057 - Train Accuracy:  0.7361111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.73015875\n",
      "epoch:  75  -  cost:  0.3676122  - MSE:  2.6404428358192766 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.71428573\n",
      "epoch:  76  -  cost:  0.32229492  - MSE:  2.4769293078164134 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  77  -  cost:  0.2912763  - MSE:  2.6784563131917856 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.6825397\n",
      "epoch:  78  -  cost:  0.2732122  - MSE:  2.807836751249847 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.74603176\n",
      "epoch:  79  -  cost:  0.2711226  - MSE:  3.4760851773959485 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.73015875\n",
      "epoch:  80  -  cost:  0.3166863  - MSE:  3.669496013729818 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.71428573\n",
      "epoch:  81  -  cost:  0.40204263  - MSE:  5.349469913176671 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.53968257\n",
      "epoch:  82  -  cost:  0.7247946  - MSE:  5.056982605238094 - Train Accuracy:  0.5972222\n",
      "Accuracy:  0.50793654\n",
      "epoch:  83  -  cost:  0.46081802  - MSE:  2.7720442426299337 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  84  -  cost:  0.3139613  - MSE:  3.441022817722861 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.73015875\n",
      "epoch:  85  -  cost:  0.30196252  - MSE:  2.9312343192694157 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.7777778\n",
      "epoch:  86  -  cost:  0.32282984  - MSE:  4.328013503366931 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.5873016\n",
      "epoch:  87  -  cost:  0.45433044  - MSE:  3.1695039052406053 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  88  -  cost:  0.30742756  - MSE:  5.37056014851816 - Train Accuracy:  0.875\n",
      "Accuracy:  0.61904764\n",
      "epoch:  89  -  cost:  0.41181284  - MSE:  3.6225439994413446 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.74603176\n",
      "epoch:  90  -  cost:  0.30139267  - MSE:  6.0119583186974594 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.6031746\n",
      "epoch:  91  -  cost:  0.42797074  - MSE:  4.342216352572749 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.73015875\n",
      "epoch:  92  -  cost:  0.3235811  - MSE:  6.800157270142667 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.5555556\n",
      "epoch:  93  -  cost:  0.48403943  - MSE:  4.254906276676918 - Train Accuracy:  0.7569444\n",
      "Accuracy:  0.74603176\n",
      "epoch:  94  -  cost:  0.29598787  - MSE:  5.805712936281577 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.61904764\n",
      "epoch:  95  -  cost:  0.36729744  - MSE:  4.342480585218124 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  96  -  cost:  0.31433365  - MSE:  7.001264624065952 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.5555556\n",
      "epoch:  97  -  cost:  0.5078458  - MSE:  4.729353226137341 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.73015875\n",
      "epoch:  98  -  cost:  0.3001846  - MSE:  6.1850915626511185 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.63492066\n",
      "epoch:  99  -  cost:  0.36580652  - MSE:  4.182791791543834 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  100  -  cost:  0.29358917  - MSE:  7.05096004319461 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.5555556\n",
      "epoch:  101  -  cost:  0.45571974  - MSE:  4.803452252020856 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.73015875\n",
      "epoch:  102  -  cost:  0.3020954  - MSE:  6.31179534941447 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.6031746\n",
      "epoch:  103  -  cost:  0.3869507  - MSE:  4.412577836490971 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.74603176\n",
      "epoch:  104  -  cost:  0.27816883  - MSE:  6.813632403018332 - Train Accuracy:  0.875\n",
      "Accuracy:  0.61904764\n",
      "epoch:  105  -  cost:  0.3533236  - MSE:  5.030877868800804 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  106  -  cost:  0.28108862  - MSE:  7.7885307385023905 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.6031746\n",
      "epoch:  107  -  cost:  0.41898406  - MSE:  5.229202247785726 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.73015875\n",
      "epoch:  108  -  cost:  0.29475367  - MSE:  7.185007936534762 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.6031746\n",
      "epoch:  109  -  cost:  0.38263786  - MSE:  4.89280139781588 - Train Accuracy:  0.8194444\n",
      "Accuracy:  0.73015875\n",
      "epoch:  110  -  cost:  0.2860358  - MSE:  7.553241169055516 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.6031746\n",
      "epoch:  111  -  cost:  0.38521978  - MSE:  5.08639133627127 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.73015875\n",
      "epoch:  112  -  cost:  0.27432317  - MSE:  7.457481486436198 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.61904764\n",
      "epoch:  113  -  cost:  0.35291827  - MSE:  5.335282908608535 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.73015875\n",
      "epoch:  114  -  cost:  0.27930075  - MSE:  8.13413934273586 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.5873016\n",
      "epoch:  115  -  cost:  0.42424962  - MSE:  5.44383006102745 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.71428573\n",
      "epoch:  116  -  cost:  0.3125929  - MSE:  7.401067359114294 - Train Accuracy:  0.8472222\n",
      "Accuracy:  0.5714286\n",
      "epoch:  117  -  cost:  0.4840532  - MSE:  5.153273139720634 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.73015875\n",
      "epoch:  118  -  cost:  0.29378065  - MSE:  7.190507915933906 - Train Accuracy:  0.875\n",
      "Accuracy:  0.5873016\n",
      "epoch:  119  -  cost:  0.3538386  - MSE:  4.497359002833916 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.7619048\n",
      "epoch:  120  -  cost:  0.22014573  - MSE:  6.748955229991554 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.73015875\n",
      "epoch:  121  -  cost:  0.21526514  - MSE:  5.971947454097459 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.7777778\n",
      "epoch:  122  -  cost:  0.207564  - MSE:  8.520060239360138 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.6507937\n",
      "epoch:  123  -  cost:  0.32187116  - MSE:  6.389117371774447 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.6984127\n",
      "epoch:  124  -  cost:  0.34166172  - MSE:  8.824106175701663 - Train Accuracy:  0.8194444\n",
      "Accuracy:  0.52380955\n",
      "epoch:  125  -  cost:  0.68186975  - MSE:  6.383274120798137 - Train Accuracy:  0.6041667\n",
      "Accuracy:  0.71428573\n",
      "epoch:  126  -  cost:  0.2611999  - MSE:  5.29698873354156 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.7936508\n",
      "epoch:  127  -  cost:  0.21672858  - MSE:  4.708442717463946 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.7936508\n",
      "epoch:  128  -  cost:  0.19246714  - MSE:  5.749315652302238 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7777778\n",
      "epoch:  129  -  cost:  0.17751488  - MSE:  6.320273009226361 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.7777778\n",
      "epoch:  130  -  cost:  0.16882093  - MSE:  6.613084791067533 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7777778\n",
      "epoch:  131  -  cost:  0.16632362  - MSE:  6.729181175949277 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7936508\n",
      "epoch:  132  -  cost:  0.16921309  - MSE:  7.615885221742001 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  133  -  cost:  0.19581977  - MSE:  6.965633373789263 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.74603176\n",
      "epoch:  134  -  cost:  0.23867981  - MSE:  10.151699489138322 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.5714286\n",
      "epoch:  135  -  cost:  0.64509296  - MSE:  8.429770390258108 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.6507937\n",
      "epoch:  136  -  cost:  0.51935047  - MSE:  6.819843852971731 - Train Accuracy:  0.7361111\n",
      "Accuracy:  0.47619048\n",
      "epoch:  137  -  cost:  0.83338344  - MSE:  3.0270513400254777 - Train Accuracy:  0.5833333\n",
      "Accuracy:  0.61904764\n",
      "epoch:  138  -  cost:  0.5864218  - MSE:  2.4885521792292633 - Train Accuracy:  0.6041667\n",
      "Accuracy:  0.6031746\n",
      "epoch:  139  -  cost:  0.44524363  - MSE:  4.089831073689308 - Train Accuracy:  0.7708333\n",
      "Accuracy:  0.73015875\n",
      "epoch:  140  -  cost:  0.25759202  - MSE:  9.344172925456412 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.7777778\n",
      "epoch:  141  -  cost:  0.20648113  - MSE:  10.23439786715089 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.74603176\n",
      "epoch:  142  -  cost:  0.21159919  - MSE:  16.038356570138124 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.6031746\n",
      "epoch:  143  -  cost:  0.49009004  - MSE:  10.843804786851559 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.5714286\n",
      "epoch:  144  -  cost:  1.225399  - MSE:  25.98325005513481 - Train Accuracy:  0.5833333\n",
      "Accuracy:  0.41269842\n",
      "epoch:  145  -  cost:  0.89099723  - MSE:  1.7113196423220296 - Train Accuracy:  0.47916666\n",
      "Accuracy:  0.46031746\n",
      "epoch:  146  -  cost:  0.7567753  - MSE:  0.927980061370142 - Train Accuracy:  0.45833334\n",
      "Accuracy:  0.6031746\n",
      "epoch:  147  -  cost:  0.6895707  - MSE:  1.0285753905988688 - Train Accuracy:  0.5277778\n",
      "Accuracy:  0.6666667\n",
      "epoch:  148  -  cost:  0.6284644  - MSE:  1.1891845255707625 - Train Accuracy:  0.6041667\n",
      "Accuracy:  0.6984127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  149  -  cost:  0.5776508  - MSE:  1.545486125074186 - Train Accuracy:  0.6736111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  150  -  cost:  0.5244279  - MSE:  2.2931956959407707 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.84126985\n",
      "epoch:  151  -  cost:  0.49097002  - MSE:  3.0738895904816355 - Train Accuracy:  0.6875\n",
      "Accuracy:  0.6507937\n",
      "epoch:  152  -  cost:  0.61644256  - MSE:  1.838654002112504 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.44444445\n",
      "epoch:  153  -  cost:  1.4119328  - MSE:  11.16578094778138 - Train Accuracy:  0.4861111\n",
      "Accuracy:  0.5714286\n",
      "epoch:  154  -  cost:  0.91618663  - MSE:  1.2698207309747156 - Train Accuracy:  0.5208333\n",
      "Accuracy:  0.50793654\n",
      "epoch:  155  -  cost:  0.67258626  - MSE:  0.5461898314322036 - Train Accuracy:  0.5347222\n",
      "Accuracy:  0.53968257\n",
      "epoch:  156  -  cost:  0.6391318  - MSE:  0.5420390600398112 - Train Accuracy:  0.5694444\n",
      "Accuracy:  0.50793654\n",
      "epoch:  157  -  cost:  0.61787426  - MSE:  0.5754301191361192 - Train Accuracy:  0.625\n",
      "Accuracy:  0.52380955\n",
      "epoch:  158  -  cost:  0.6001863  - MSE:  0.6643696824239583 - Train Accuracy:  0.75\n",
      "Accuracy:  0.63492066\n",
      "epoch:  159  -  cost:  0.5651978  - MSE:  0.818317283501205 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.6031746\n",
      "epoch:  160  -  cost:  0.48414966  - MSE:  1.096615446993892 - Train Accuracy:  0.7986111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  161  -  cost:  0.40803087  - MSE:  1.9718500559327927 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.6031746\n",
      "epoch:  162  -  cost:  0.40714985  - MSE:  2.0348283312144106 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.6825397\n",
      "epoch:  163  -  cost:  0.6482456  - MSE:  5.942885304126575 - Train Accuracy:  0.6597222\n",
      "Accuracy:  0.47619048\n",
      "epoch:  164  -  cost:  1.0005864  - MSE:  5.1455719430486075 - Train Accuracy:  0.5486111\n",
      "Accuracy:  0.4920635\n",
      "epoch:  165  -  cost:  0.66986233  - MSE:  1.016006797016856 - Train Accuracy:  0.5555556\n",
      "Accuracy:  0.6507937\n",
      "epoch:  166  -  cost:  0.4875641  - MSE:  0.8205991592338922 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.71428573\n",
      "epoch:  167  -  cost:  0.3966583  - MSE:  1.4782782297240482 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  168  -  cost:  0.38370472  - MSE:  1.0411168479556003 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  169  -  cost:  0.3956507  - MSE:  2.3772363630406543 - Train Accuracy:  0.8125\n",
      "Accuracy:  0.61904764\n",
      "epoch:  170  -  cost:  0.49815497  - MSE:  1.1500165338876287 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.71428573\n",
      "epoch:  171  -  cost:  0.3336307  - MSE:  1.93844514189011 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  172  -  cost:  0.3383554  - MSE:  1.4716319263008084 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.73015875\n",
      "epoch:  173  -  cost:  0.36368978  - MSE:  2.7422479290098867 - Train Accuracy:  0.8194444\n",
      "Accuracy:  0.5873016\n",
      "epoch:  174  -  cost:  0.50679165  - MSE:  1.9763339594810567 - Train Accuracy:  0.7361111\n",
      "Accuracy:  0.7619048\n",
      "epoch:  175  -  cost:  0.30187735  - MSE:  2.329932411596473 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.6666667\n",
      "epoch:  176  -  cost:  0.3115031  - MSE:  1.9796128867451102 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  177  -  cost:  0.35375744  - MSE:  3.286105893277215 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.5555556\n",
      "epoch:  178  -  cost:  0.5664622  - MSE:  3.260382105633883 - Train Accuracy:  0.7083333\n",
      "Accuracy:  0.74603176\n",
      "epoch:  179  -  cost:  0.31756353  - MSE:  2.5560397066258234 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.6666667\n",
      "epoch:  180  -  cost:  0.36332402  - MSE:  1.9515012080464953 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  181  -  cost:  0.26379025  - MSE:  2.6283554418853328 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.71428573\n",
      "epoch:  182  -  cost:  0.25284147  - MSE:  2.2847280748440784 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.7619048\n",
      "epoch:  183  -  cost:  0.23857433  - MSE:  2.9649073424042336 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.71428573\n",
      "epoch:  184  -  cost:  0.25548267  - MSE:  2.8628483397595885 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.7619048\n",
      "epoch:  185  -  cost:  0.28167084  - MSE:  3.7778785670373103 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.61904764\n",
      "epoch:  186  -  cost:  0.48646927  - MSE:  4.483193534661899 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.7619048\n",
      "epoch:  187  -  cost:  0.41877353  - MSE:  4.592080871873193 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.5555556\n",
      "epoch:  188  -  cost:  0.7377554  - MSE:  3.9395210227049517 - Train Accuracy:  0.625\n",
      "Accuracy:  0.6031746\n",
      "epoch:  189  -  cost:  0.44720426  - MSE:  1.578102829098704 - Train Accuracy:  0.7916667\n",
      "Accuracy:  0.73015875\n",
      "epoch:  190  -  cost:  0.26218927  - MSE:  2.9505095254923113 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.74603176\n",
      "epoch:  191  -  cost:  0.24389812  - MSE:  2.5458466697623447 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.74603176\n",
      "epoch:  192  -  cost:  0.22907516  - MSE:  2.756213698400434 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.74603176\n",
      "epoch:  193  -  cost:  0.21778336  - MSE:  2.838582738724435 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.74603176\n",
      "epoch:  194  -  cost:  0.20750676  - MSE:  3.0996061502677312 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.7619048\n",
      "epoch:  195  -  cost:  0.19556345  - MSE:  3.268794878938943 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.74603176\n",
      "epoch:  196  -  cost:  0.18345533  - MSE:  3.6809722224811448 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.7619048\n",
      "epoch:  197  -  cost:  0.17430116  - MSE:  3.8504008693959504 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.74603176\n",
      "epoch:  198  -  cost:  0.16724664  - MSE:  4.266675319250316 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.73015875\n",
      "epoch:  199  -  cost:  0.17860496  - MSE:  4.612436495251229 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.7619048\n",
      "epoch:  200  -  cost:  0.25647953  - MSE:  5.660711302525611 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.5714286\n",
      "epoch:  201  -  cost:  0.61996204  - MSE:  7.54793440482655 - Train Accuracy:  0.7152778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  202  -  cost:  0.8353455  - MSE:  8.101563772678848 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.44444445\n",
      "epoch:  203  -  cost:  1.0867549  - MSE:  4.592813207097315 - Train Accuracy:  0.5416667\n",
      "Accuracy:  0.52380955\n",
      "epoch:  204  -  cost:  0.69303966  - MSE:  0.9987196190377075 - Train Accuracy:  0.5347222\n",
      "Accuracy:  0.6825397\n",
      "epoch:  205  -  cost:  0.6449286  - MSE:  0.7203710188428035 - Train Accuracy:  0.625\n",
      "Accuracy:  0.6825397\n",
      "epoch:  206  -  cost:  0.6176903  - MSE:  0.7367585132901961 - Train Accuracy:  0.6111111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  207  -  cost:  0.5971488  - MSE:  0.6851586826059846 - Train Accuracy:  0.6875\n",
      "Accuracy:  0.6825397\n",
      "epoch:  208  -  cost:  0.583812  - MSE:  0.699707527975947 - Train Accuracy:  0.6736111\n",
      "Accuracy:  0.73015875\n",
      "epoch:  209  -  cost:  0.57143784  - MSE:  0.6937807058557367 - Train Accuracy:  0.7013889\n",
      "Accuracy:  0.71428573\n",
      "epoch:  210  -  cost:  0.5598392  - MSE:  0.7390589837268012 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.73015875\n",
      "epoch:  211  -  cost:  0.54954636  - MSE:  0.7575858264193404 - Train Accuracy:  0.7083333\n",
      "Accuracy:  0.6984127\n",
      "epoch:  212  -  cost:  0.5416626  - MSE:  0.8160792953257235 - Train Accuracy:  0.6875\n",
      "Accuracy:  0.73015875\n",
      "epoch:  213  -  cost:  0.5329256  - MSE:  0.8462243507565791 - Train Accuracy:  0.7083333\n",
      "Accuracy:  0.71428573\n",
      "epoch:  214  -  cost:  0.5251222  - MSE:  0.8998378258211097 - Train Accuracy:  0.7152778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  215  -  cost:  0.51764023  - MSE:  0.8827803440862649 - Train Accuracy:  0.7083333\n",
      "Accuracy:  0.73015875\n",
      "epoch:  216  -  cost:  0.51234424  - MSE:  1.0167624081010689 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.73015875\n",
      "epoch:  217  -  cost:  0.50280833  - MSE:  0.9595083220730848 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.73015875\n",
      "epoch:  218  -  cost:  0.4949847  - MSE:  1.0574029215000338 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.7619048\n",
      "epoch:  219  -  cost:  0.48816144  - MSE:  1.0994029714992466 - Train Accuracy:  0.7569444\n",
      "Accuracy:  0.7619048\n",
      "epoch:  220  -  cost:  0.48560756  - MSE:  1.1770011906859732 - Train Accuracy:  0.7569444\n",
      "Accuracy:  0.7777778\n",
      "epoch:  221  -  cost:  0.47503608  - MSE:  1.2017376021653232 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.73015875\n",
      "epoch:  222  -  cost:  0.47101715  - MSE:  1.3047432763703612 - Train Accuracy:  0.7708333\n",
      "Accuracy:  0.7619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  223  -  cost:  0.46656144  - MSE:  1.2891828417453772 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.6825397\n",
      "epoch:  224  -  cost:  0.47640106  - MSE:  1.491116344740571 - Train Accuracy:  0.7361111\n",
      "Accuracy:  0.7777778\n",
      "epoch:  225  -  cost:  0.48593676  - MSE:  1.562777419848846 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.5873016\n",
      "epoch:  226  -  cost:  0.5332741  - MSE:  1.9148529971044794 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.71428573\n",
      "epoch:  227  -  cost:  0.51618373  - MSE:  1.6598733418481424 - Train Accuracy:  0.7361111\n",
      "Accuracy:  0.50793654\n",
      "epoch:  228  -  cost:  0.55990684  - MSE:  2.0997830427551043 - Train Accuracy:  0.625\n",
      "Accuracy:  0.7619048\n",
      "epoch:  229  -  cost:  0.4756811  - MSE:  1.7995689571519222 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.6031746\n",
      "epoch:  230  -  cost:  0.47339332  - MSE:  1.8898488817774142 - Train Accuracy:  0.75\n",
      "Accuracy:  0.74603176\n",
      "epoch:  231  -  cost:  0.44357017  - MSE:  1.9047869340195933 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.61904764\n",
      "epoch:  232  -  cost:  0.4532565  - MSE:  2.135211965556344 - Train Accuracy:  0.7569444\n",
      "Accuracy:  0.7619048\n",
      "epoch:  233  -  cost:  0.46004242  - MSE:  2.1284796719114336 - Train Accuracy:  0.7708333\n",
      "Accuracy:  0.5873016\n",
      "epoch:  234  -  cost:  0.47438514  - MSE:  2.461036816802361 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.74603176\n",
      "epoch:  235  -  cost:  0.4607486  - MSE:  2.200509144914361 - Train Accuracy:  0.7708333\n",
      "Accuracy:  0.5873016\n",
      "epoch:  236  -  cost:  0.46834803  - MSE:  2.446319993743278 - Train Accuracy:  0.7291667\n",
      "Accuracy:  0.74603176\n",
      "epoch:  237  -  cost:  0.43080983  - MSE:  2.412858659956123 - Train Accuracy:  0.7986111\n",
      "Accuracy:  0.6507937\n",
      "epoch:  238  -  cost:  0.43913406  - MSE:  2.5239380864661136 - Train Accuracy:  0.7777778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  239  -  cost:  0.45554173  - MSE:  2.5074970896783744 - Train Accuracy:  0.7708333\n",
      "Accuracy:  0.61904764\n",
      "epoch:  240  -  cost:  0.45128265  - MSE:  2.751687840982355 - Train Accuracy:  0.75\n",
      "Accuracy:  0.7619048\n",
      "epoch:  241  -  cost:  0.41621643  - MSE:  2.0828272015997213 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.63492066\n",
      "epoch:  242  -  cost:  0.4382436  - MSE:  2.4941480069398896 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  243  -  cost:  0.45963076  - MSE:  2.735672574890831 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.63492066\n",
      "epoch:  244  -  cost:  0.45770168  - MSE:  3.0292617291223616 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.74603176\n",
      "epoch:  245  -  cost:  0.40199125  - MSE:  2.5178125662877338 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.6666667\n",
      "epoch:  246  -  cost:  0.40859345  - MSE:  2.911868526989204 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.74603176\n",
      "epoch:  247  -  cost:  0.41140497  - MSE:  3.053047618040833 - Train Accuracy:  0.8194444\n",
      "Accuracy:  0.63492066\n",
      "epoch:  248  -  cost:  0.42535183  - MSE:  3.393934536650958 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.6984127\n",
      "epoch:  249  -  cost:  0.43838453  - MSE:  3.3176016638102985 - Train Accuracy:  0.7847222\n",
      "Accuracy:  0.6031746\n",
      "epoch:  250  -  cost:  0.44105506  - MSE:  3.753024855660269 - Train Accuracy:  0.75\n",
      "Accuracy:  0.71428573\n",
      "epoch:  251  -  cost:  0.39911023  - MSE:  3.4062102729353616 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.74603176\n",
      "epoch:  252  -  cost:  0.3776126  - MSE:  3.501104704539045 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.7619048\n",
      "epoch:  253  -  cost:  0.34952116  - MSE:  3.63974433345996 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.7619048\n",
      "epoch:  254  -  cost:  0.32067323  - MSE:  3.816363941330655 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.7777778\n",
      "epoch:  255  -  cost:  0.3179445  - MSE:  3.906341138991068 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.71428573\n",
      "epoch:  256  -  cost:  0.35157874  - MSE:  4.2928268603535 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.6984127\n",
      "epoch:  257  -  cost:  0.5136193  - MSE:  5.3565833279249615 - Train Accuracy:  0.7361111\n",
      "Accuracy:  0.5555556\n",
      "epoch:  258  -  cost:  0.60296845  - MSE:  5.432256630142794 - Train Accuracy:  0.6666667\n",
      "Accuracy:  0.71428573\n",
      "epoch:  259  -  cost:  0.38799536  - MSE:  3.9319810402528526 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.82539684\n",
      "epoch:  260  -  cost:  0.31087548  - MSE:  3.6472633366863643 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.7936508\n",
      "epoch:  261  -  cost:  0.29358926  - MSE:  4.497986941375059 - Train Accuracy:  0.875\n",
      "Accuracy:  0.7619048\n",
      "epoch:  262  -  cost:  0.2906431  - MSE:  4.530840556513799 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.7619048\n",
      "epoch:  263  -  cost:  0.3506366  - MSE:  5.1612777924725695 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.61904764\n",
      "epoch:  264  -  cost:  0.46897507  - MSE:  5.384216997077615 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.6507937\n",
      "epoch:  265  -  cost:  0.64066136  - MSE:  7.717152166063121 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.50793654\n",
      "epoch:  266  -  cost:  0.5782282  - MSE:  6.164733851989195 - Train Accuracy:  0.6527778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  267  -  cost:  0.4264803  - MSE:  4.590653454987706 - Train Accuracy:  0.7986111\n",
      "Accuracy:  0.7619048\n",
      "epoch:  268  -  cost:  0.32267246  - MSE:  5.55449529382675 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.7777778\n",
      "epoch:  269  -  cost:  0.28383976  - MSE:  6.8852613006394074 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.7777778\n",
      "epoch:  270  -  cost:  0.2583588  - MSE:  7.596766143013864 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  271  -  cost:  0.2379274  - MSE:  7.859503309598894 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.7936508\n",
      "epoch:  272  -  cost:  0.22098312  - MSE:  8.341193530363642 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.8095238\n",
      "epoch:  273  -  cost:  0.20882916  - MSE:  8.940008734882127 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.8095238\n",
      "epoch:  274  -  cost:  0.19610183  - MSE:  9.423374273964154 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.8095238\n",
      "epoch:  275  -  cost:  0.18417674  - MSE:  9.655126477527672 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.82539684\n",
      "epoch:  276  -  cost:  0.17559923  - MSE:  10.161237373126657 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.8095238\n",
      "epoch:  277  -  cost:  0.17086056  - MSE:  10.116717389050189 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.8095238\n",
      "epoch:  278  -  cost:  0.18346234  - MSE:  11.843323811674605 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.71428573\n",
      "epoch:  279  -  cost:  0.29213545  - MSE:  9.655541612598519 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.63492066\n",
      "epoch:  280  -  cost:  1.2805166  - MSE:  23.659982078942697 - Train Accuracy:  0.6180556\n",
      "Accuracy:  0.42857143\n",
      "epoch:  281  -  cost:  2.1266718  - MSE:  9.322740801887216 - Train Accuracy:  0.47916666\n",
      "Accuracy:  0.46031746\n",
      "epoch:  282  -  cost:  0.61833775  - MSE:  0.9138538215928802 - Train Accuracy:  0.6388889\n",
      "Accuracy:  0.42857143\n",
      "epoch:  283  -  cost:  0.58300304  - MSE:  0.9354904204383905 - Train Accuracy:  0.6527778\n",
      "Accuracy:  0.46031746\n",
      "epoch:  284  -  cost:  0.5625391  - MSE:  0.9664589342949912 - Train Accuracy:  0.6458333\n",
      "Accuracy:  0.4920635\n",
      "epoch:  285  -  cost:  0.54775643  - MSE:  0.9543212059310102 - Train Accuracy:  0.6597222\n",
      "Accuracy:  0.53968257\n",
      "epoch:  286  -  cost:  0.53585297  - MSE:  0.946270314732571 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.5555556\n",
      "epoch:  287  -  cost:  0.52510715  - MSE:  0.9784389830745561 - Train Accuracy:  0.7013889\n",
      "Accuracy:  0.6031746\n",
      "epoch:  288  -  cost:  0.51519907  - MSE:  0.9889076754771434 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.6031746\n",
      "epoch:  289  -  cost:  0.50589794  - MSE:  1.038996700758095 - Train Accuracy:  0.7638889\n",
      "Accuracy:  0.6031746\n",
      "epoch:  290  -  cost:  0.49717438  - MSE:  1.0582382327141364 - Train Accuracy:  0.7916667\n",
      "Accuracy:  0.5873016\n",
      "epoch:  291  -  cost:  0.48810884  - MSE:  1.1095622892267432 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.6666667\n",
      "epoch:  292  -  cost:  0.47915253  - MSE:  1.0962853860479123 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.5873016\n",
      "epoch:  293  -  cost:  0.46855247  - MSE:  1.158747225477281 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.6984127\n",
      "epoch:  294  -  cost:  0.4571307  - MSE:  1.1979577437986784 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.6825397\n",
      "epoch:  295  -  cost:  0.44404098  - MSE:  1.255646915686692 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.6666667\n",
      "epoch:  296  -  cost:  0.43369526  - MSE:  1.2957269582831268 - Train Accuracy:  0.8402778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666667\n",
      "epoch:  297  -  cost:  0.42218602  - MSE:  1.2748419003017153 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  298  -  cost:  0.407175  - MSE:  1.3657578630560796 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.74603176\n",
      "epoch:  299  -  cost:  0.39216152  - MSE:  1.4317091423087187 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.74603176\n",
      "epoch:  300  -  cost:  0.37944645  - MSE:  1.4652558159562348 - Train Accuracy:  0.875\n",
      "Accuracy:  0.7619048\n",
      "epoch:  301  -  cost:  0.36631328  - MSE:  1.6311079360337881 - Train Accuracy:  0.875\n",
      "Accuracy:  0.74603176\n",
      "epoch:  302  -  cost:  0.35318473  - MSE:  1.815351382521548 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.7777778\n",
      "epoch:  303  -  cost:  0.33875316  - MSE:  2.110777676269797 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.7777778\n",
      "epoch:  304  -  cost:  0.3208807  - MSE:  2.585515701276149 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.7936508\n",
      "epoch:  305  -  cost:  0.30818674  - MSE:  2.724703378639291 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.7777778\n",
      "epoch:  306  -  cost:  0.2957111  - MSE:  3.193928357041425 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.7777778\n",
      "epoch:  307  -  cost:  0.28446114  - MSE:  3.451119072440342 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.7619048\n",
      "epoch:  308  -  cost:  0.27502856  - MSE:  4.053023235763792 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.7777778\n",
      "epoch:  309  -  cost:  0.27098358  - MSE:  4.030997266313609 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  310  -  cost:  0.28426492  - MSE:  4.793778625633105 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.63492066\n",
      "epoch:  311  -  cost:  0.356247  - MSE:  4.446340986464133 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.6666667\n",
      "epoch:  312  -  cost:  0.601125  - MSE:  7.119565032281532 - Train Accuracy:  0.6597222\n",
      "Accuracy:  0.4920635\n",
      "epoch:  313  -  cost:  0.9601705  - MSE:  5.475805658784403 - Train Accuracy:  0.5833333\n",
      "Accuracy:  0.6825397\n",
      "epoch:  314  -  cost:  0.5721034  - MSE:  8.034777727420396 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.6666667\n",
      "epoch:  315  -  cost:  0.3922118  - MSE:  4.322468529499955 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.7777778\n",
      "epoch:  316  -  cost:  0.30769348  - MSE:  5.779350070496693 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.74603176\n",
      "epoch:  317  -  cost:  0.2773955  - MSE:  7.030637165963382 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.74603176\n",
      "epoch:  318  -  cost:  0.25167832  - MSE:  7.572763480427614 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.7777778\n",
      "epoch:  319  -  cost:  0.23002976  - MSE:  8.640591783398918 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.74603176\n",
      "epoch:  320  -  cost:  0.21488616  - MSE:  8.360755124962045 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.7777778\n",
      "epoch:  321  -  cost:  0.23226124  - MSE:  10.622424620506285 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.6507937\n",
      "epoch:  322  -  cost:  0.3274916  - MSE:  6.939796037739703 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.73015875\n",
      "epoch:  323  -  cost:  0.27829146  - MSE:  12.4905781930062 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.61904764\n",
      "epoch:  324  -  cost:  0.3820901  - MSE:  6.903195881015164 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.73015875\n",
      "epoch:  325  -  cost:  0.34505373  - MSE:  11.449185230827982 - Train Accuracy:  0.8402778\n",
      "Accuracy:  0.52380955\n",
      "epoch:  326  -  cost:  0.51933956  - MSE:  4.961808664838517 - Train Accuracy:  0.6666667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  327  -  cost:  0.26764026  - MSE:  7.395578555597443 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.74603176\n",
      "epoch:  328  -  cost:  0.2220745  - MSE:  7.861861876093173 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.8095238\n",
      "epoch:  329  -  cost:  0.1991461  - MSE:  10.437108623771312 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.82539684\n",
      "epoch:  330  -  cost:  0.17965671  - MSE:  10.736390887001779 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.82539684\n",
      "epoch:  331  -  cost:  0.17167753  - MSE:  12.161847930527431 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.82539684\n",
      "epoch:  332  -  cost:  0.17410637  - MSE:  10.871013237277246 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.8095238\n",
      "epoch:  333  -  cost:  0.18569809  - MSE:  13.487332248596163 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.6984127\n",
      "epoch:  334  -  cost:  0.26358894  - MSE:  8.982757603077864 - Train Accuracy:  0.875\n",
      "Accuracy:  0.73015875\n",
      "epoch:  335  -  cost:  0.30433348  - MSE:  16.68778276604288 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.5555556\n",
      "epoch:  336  -  cost:  0.5933931  - MSE:  7.160455582808078 - Train Accuracy:  0.6736111\n",
      "Accuracy:  0.73015875\n",
      "epoch:  337  -  cost:  0.3670665  - MSE:  12.134956259175299 - Train Accuracy:  0.8472222\n",
      "Accuracy:  0.63492066\n",
      "epoch:  338  -  cost:  0.3703449  - MSE:  4.7697816789826755 - Train Accuracy:  0.7986111\n",
      "Accuracy:  0.74603176\n",
      "epoch:  339  -  cost:  0.23583606  - MSE:  9.79392719809118 - Train Accuracy:  0.875\n",
      "Accuracy:  0.7936508\n",
      "epoch:  340  -  cost:  0.21286903  - MSE:  7.362402321335797 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.82539684\n",
      "epoch:  341  -  cost:  0.17232014  - MSE:  10.456273495109041 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.7936508\n",
      "epoch:  342  -  cost:  0.15748042  - MSE:  10.126564966959721 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.82539684\n",
      "epoch:  343  -  cost:  0.15769298  - MSE:  13.212902160656752 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.74603176\n",
      "epoch:  344  -  cost:  0.19690722  - MSE:  9.239224223619562 - Train Accuracy:  0.9166667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  345  -  cost:  0.19870645  - MSE:  15.590750040633292 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  346  -  cost:  0.31824315  - MSE:  8.312681129299644 - Train Accuracy:  0.8541667\n",
      "Accuracy:  0.73015875\n",
      "epoch:  347  -  cost:  0.31482702  - MSE:  18.35057822607194 - Train Accuracy:  0.8472222\n",
      "Accuracy:  0.53968257\n",
      "epoch:  348  -  cost:  0.5650435  - MSE:  6.908931388703131 - Train Accuracy:  0.6805556\n",
      "Accuracy:  0.73015875\n",
      "epoch:  349  -  cost:  0.3953833  - MSE:  12.357973426158692 - Train Accuracy:  0.8333333\n",
      "Accuracy:  0.5555556\n",
      "epoch:  350  -  cost:  0.4598824  - MSE:  4.671164469687594 - Train Accuracy:  0.7430556\n",
      "Accuracy:  0.8095238\n",
      "epoch:  351  -  cost:  0.24029382  - MSE:  8.165301425564817 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.8095238\n",
      "epoch:  352  -  cost:  0.17780243  - MSE:  7.986707046727309 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.82539684\n",
      "epoch:  353  -  cost:  0.15494677  - MSE:  10.383296688426055 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.7936508\n",
      "epoch:  354  -  cost:  0.14376336  - MSE:  10.096225573431779 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.8095238\n",
      "epoch:  355  -  cost:  0.1388765  - MSE:  12.679292562786506 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.82539684\n",
      "epoch:  356  -  cost:  0.14157248  - MSE:  10.908935182779006 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.8095238\n",
      "epoch:  357  -  cost:  0.14054441  - MSE:  14.126390837071773 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.7777778\n",
      "epoch:  358  -  cost:  0.15764345  - MSE:  10.329727148345466 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.7936508\n",
      "epoch:  359  -  cost:  0.153913  - MSE:  15.30130046486432 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.73015875\n",
      "epoch:  360  -  cost:  0.2119644  - MSE:  9.391301303363504 - Train Accuracy:  0.9027778\n",
      "Accuracy:  0.7619048\n",
      "epoch:  361  -  cost:  0.26214987  - MSE:  20.22729359877587 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.53968257\n",
      "epoch:  362  -  cost:  0.49153784  - MSE:  6.632354901783206 - Train Accuracy:  0.7222222\n",
      "Accuracy:  0.6984127\n",
      "epoch:  363  -  cost:  0.32983962  - MSE:  15.869883619896676 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.63492066\n",
      "epoch:  364  -  cost:  0.3368257  - MSE:  6.135102943851356 - Train Accuracy:  0.8055556\n",
      "Accuracy:  0.7619048\n",
      "epoch:  365  -  cost:  0.18950197  - MSE:  11.213418950488187 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.8095238\n",
      "epoch:  366  -  cost:  0.14714469  - MSE:  9.028852401221462 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.8095238\n",
      "epoch:  367  -  cost:  0.12685  - MSE:  12.648457345858798 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.8095238\n",
      "epoch:  368  -  cost:  0.11622731  - MSE:  12.095709823574188 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.8095238\n",
      "epoch:  369  -  cost:  0.11307955  - MSE:  14.692191177912605 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.85714287\n",
      "epoch:  370  -  cost:  0.11871269  - MSE:  11.887063820461373 - Train Accuracy:  0.9652778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8095238\n",
      "epoch:  371  -  cost:  0.1131867  - MSE:  16.178571958501838 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.7936508\n",
      "epoch:  372  -  cost:  0.13202208  - MSE:  11.168232590265276 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.7936508\n",
      "epoch:  373  -  cost:  0.1402447  - MSE:  18.14235579006503 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  374  -  cost:  0.18920057  - MSE:  9.948554231076667 - Train Accuracy:  0.9097222\n",
      "Accuracy:  0.7619048\n",
      "epoch:  375  -  cost:  0.27219394  - MSE:  21.357620207135948 - Train Accuracy:  0.875\n",
      "Accuracy:  0.53968257\n",
      "epoch:  376  -  cost:  0.6673658  - MSE:  6.317142207383456 - Train Accuracy:  0.6527778\n",
      "Accuracy:  0.71428573\n",
      "epoch:  377  -  cost:  0.5896615  - MSE:  19.227482690681107 - Train Accuracy:  0.7291667\n",
      "Accuracy:  0.53968257\n",
      "epoch:  378  -  cost:  0.7164211  - MSE:  3.9996546596131415 - Train Accuracy:  0.5902778\n",
      "Accuracy:  0.7619048\n",
      "epoch:  379  -  cost:  0.33395734  - MSE:  2.910269633240208 - Train Accuracy:  0.8611111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  380  -  cost:  0.26515564  - MSE:  3.2881026984033697 - Train Accuracy:  0.8819444\n",
      "Accuracy:  0.7777778\n",
      "epoch:  381  -  cost:  0.20507456  - MSE:  4.800409100330587 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  382  -  cost:  0.17355005  - MSE:  5.120954736752888 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.82539684\n",
      "epoch:  383  -  cost:  0.1491951  - MSE:  6.133859351000308 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.82539684\n",
      "epoch:  384  -  cost:  0.13290924  - MSE:  6.244072931086475 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.84126985\n",
      "epoch:  385  -  cost:  0.12000027  - MSE:  7.000676593054915 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.82539684\n",
      "epoch:  386  -  cost:  0.108690195  - MSE:  7.455753713418767 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.84126985\n",
      "epoch:  387  -  cost:  0.10032871  - MSE:  8.76155202847213 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  388  -  cost:  0.09402067  - MSE:  8.478024409428555 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.85714287\n",
      "epoch:  389  -  cost:  0.09572735  - MSE:  10.428883015635675 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7777778\n",
      "epoch:  390  -  cost:  0.11288074  - MSE:  8.102569210162166 - Train Accuracy:  0.9583333\n",
      "Accuracy:  0.7936508\n",
      "epoch:  391  -  cost:  0.17168164  - MSE:  14.218446096268412 - Train Accuracy:  0.9444444\n",
      "Accuracy:  0.73015875\n",
      "epoch:  392  -  cost:  0.20594892  - MSE:  7.525756975974652 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.7619048\n",
      "epoch:  393  -  cost:  0.27817625  - MSE:  17.614368682147525 - Train Accuracy:  0.875\n",
      "Accuracy:  0.6666667\n",
      "epoch:  394  -  cost:  0.32954088  - MSE:  6.301099250275884 - Train Accuracy:  0.8263889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  395  -  cost:  0.21859409  - MSE:  13.417251442571587 - Train Accuracy:  0.9236111\n",
      "Accuracy:  0.7777778\n",
      "epoch:  396  -  cost:  0.14660478  - MSE:  7.87766913898876 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.82539684\n",
      "epoch:  397  -  cost:  0.097638436  - MSE:  10.904911748588109 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7619048\n",
      "epoch:  398  -  cost:  0.08960491  - MSE:  9.24452767416947 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  399  -  cost:  0.0776773  - MSE:  11.2406693299316 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.7777778\n",
      "epoch:  400  -  cost:  0.07461371  - MSE:  10.335758572918847 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.84126985\n",
      "epoch:  401  -  cost:  0.06971061  - MSE:  12.059028644389278 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.7777778\n",
      "epoch:  402  -  cost:  0.068541296  - MSE:  11.032443080147855 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.84126985\n",
      "epoch:  403  -  cost:  0.06721405  - MSE:  12.990980138959301 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.7936508\n",
      "epoch:  404  -  cost:  0.06914229  - MSE:  11.282489135036258 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  405  -  cost:  0.07446424  - MSE:  14.463346012810923 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.8095238\n",
      "epoch:  406  -  cost:  0.07379997  - MSE:  11.423090680176818 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  407  -  cost:  0.08725018  - MSE:  16.58775348118487 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7777778\n",
      "epoch:  408  -  cost:  0.093618326  - MSE:  11.077748896264973 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  409  -  cost:  0.13432638  - MSE:  19.586712036855484 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.73015875\n",
      "epoch:  410  -  cost:  0.2032187  - MSE:  9.504862519321536 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.73015875\n",
      "epoch:  411  -  cost:  0.36511347  - MSE:  24.738314096083624 - Train Accuracy:  0.8680556\n",
      "Accuracy:  0.5555556\n",
      "epoch:  412  -  cost:  0.85059536  - MSE:  6.872149697926733 - Train Accuracy:  0.6527778\n",
      "Accuracy:  0.6825397\n",
      "epoch:  413  -  cost:  0.7084353  - MSE:  17.5094772388888 - Train Accuracy:  0.6805556\n",
      "Accuracy:  0.53968257\n",
      "epoch:  414  -  cost:  0.60142213  - MSE:  5.84577685084035 - Train Accuracy:  0.7013889\n",
      "Accuracy:  0.74603176\n",
      "epoch:  415  -  cost:  0.21602222  - MSE:  8.784351966317013 - Train Accuracy:  0.9305556\n",
      "Accuracy:  0.7777778\n",
      "epoch:  416  -  cost:  0.16474809  - MSE:  8.09188467789814 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.7936508\n",
      "epoch:  417  -  cost:  0.14781366  - MSE:  10.960517525429438 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.8095238\n",
      "epoch:  418  -  cost:  0.13812572  - MSE:  9.529149018731925 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.7936508\n",
      "epoch:  419  -  cost:  0.1272289  - MSE:  11.655065619732113 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  420  -  cost:  0.11975433  - MSE:  10.343866985060062 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  421  -  cost:  0.112531796  - MSE:  12.345089817007176 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  422  -  cost:  0.10854034  - MSE:  10.503042103168097 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  423  -  cost:  0.104088016  - MSE:  13.190080679401227 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  424  -  cost:  0.09972337  - MSE:  11.002373110643013 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.8095238\n",
      "epoch:  425  -  cost:  0.08968246  - MSE:  14.223588880446842 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.8095238\n",
      "epoch:  426  -  cost:  0.08473368  - MSE:  11.999653815151369 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.8095238\n",
      "epoch:  427  -  cost:  0.07761193  - MSE:  14.376029498269144 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.8095238\n",
      "epoch:  428  -  cost:  0.074111976  - MSE:  13.190007227045873 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.8095238\n",
      "epoch:  429  -  cost:  0.06873059  - MSE:  14.406806284534161 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  430  -  cost:  0.065422684  - MSE:  14.765817950344113 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  431  -  cost:  0.06270689  - MSE:  15.225148764556737 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.7936508\n",
      "epoch:  432  -  cost:  0.060825646  - MSE:  14.980865061451153 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.7936508\n",
      "epoch:  433  -  cost:  0.05819461  - MSE:  15.901465856205213 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.8095238\n",
      "epoch:  434  -  cost:  0.056058235  - MSE:  15.140393647108562 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  435  -  cost:  0.053436425  - MSE:  16.448731529538446 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  436  -  cost:  0.053438317  - MSE:  15.190080100131954 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.8095238\n",
      "epoch:  437  -  cost:  0.051173534  - MSE:  17.355567948436544 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  438  -  cost:  0.05480075  - MSE:  14.972668044373101 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.8095238\n",
      "epoch:  439  -  cost:  0.05323061  - MSE:  18.527740768853565 - Train Accuracy:  0.9791667\n",
      "Accuracy:  0.82539684\n",
      "epoch:  440  -  cost:  0.07188484  - MSE:  13.98047033389605 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  441  -  cost:  0.0669963  - MSE:  20.10857368546525 - Train Accuracy:  0.9722222\n",
      "Accuracy:  0.7777778\n",
      "epoch:  442  -  cost:  0.10529294  - MSE:  12.773123236962775 - Train Accuracy:  0.9652778\n",
      "Accuracy:  0.82539684\n",
      "epoch:  443  -  cost:  0.11625457  - MSE:  22.588641223653813 - Train Accuracy:  0.9375\n",
      "Accuracy:  0.71428573\n",
      "epoch:  444  -  cost:  0.27434027  - MSE:  10.568160475216049 - Train Accuracy:  0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7619048\n",
      "epoch:  445  -  cost:  0.28194872  - MSE:  26.565075186117067 - Train Accuracy:  0.8888889\n",
      "Accuracy:  0.5555556\n",
      "epoch:  446  -  cost:  0.5583646  - MSE:  8.048427275057373 - Train Accuracy:  0.6944444\n",
      "Accuracy:  0.71428573\n",
      "epoch:  447  -  cost:  0.24830474  - MSE:  14.626647103554276 - Train Accuracy:  0.8958333\n",
      "Accuracy:  0.73015875\n",
      "epoch:  448  -  cost:  0.14782868  - MSE:  7.538575285547935 - Train Accuracy:  0.9513889\n",
      "Accuracy:  0.84126985\n",
      "epoch:  449  -  cost:  0.07579046  - MSE:  11.315745120509204 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  450  -  cost:  0.06507107  - MSE:  11.288501665070068 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.82539684\n",
      "epoch:  451  -  cost:  0.058941737  - MSE:  12.111071451679688 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  452  -  cost:  0.054536343  - MSE:  12.276413390821402 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  453  -  cost:  0.050483927  - MSE:  12.691230435268961 - Train Accuracy:  0.9861111\n",
      "Accuracy:  0.84126985\n",
      "epoch:  454  -  cost:  0.04741679  - MSE:  13.057695828354284 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.84126985\n",
      "epoch:  455  -  cost:  0.04459764  - MSE:  13.360788084199417 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.84126985\n",
      "epoch:  456  -  cost:  0.04194796  - MSE:  13.612266898215646 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.84126985\n",
      "epoch:  457  -  cost:  0.03984047  - MSE:  14.107698138148683 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.82539684\n",
      "epoch:  458  -  cost:  0.037788484  - MSE:  13.864843024536643 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.84126985\n",
      "epoch:  459  -  cost:  0.03654935  - MSE:  15.170255753956392 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  460  -  cost:  0.03533721  - MSE:  13.951279712508985 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.82539684\n",
      "epoch:  461  -  cost:  0.034092642  - MSE:  15.890579599101223 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  462  -  cost:  0.032595392  - MSE:  14.248792845215348 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.82539684\n",
      "epoch:  463  -  cost:  0.030771486  - MSE:  16.15207718014883 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  464  -  cost:  0.028722027  - MSE:  14.899877477433746 - Train Accuracy:  0.9930556\n",
      "Accuracy:  0.8095238\n",
      "epoch:  465  -  cost:  0.02707525  - MSE:  16.064406498056396 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  466  -  cost:  0.026013387  - MSE:  15.40085878070195 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  467  -  cost:  0.024703538  - MSE:  16.17969168454633 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  468  -  cost:  0.023834527  - MSE:  15.909071108129515 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  469  -  cost:  0.02290868  - MSE:  16.642940469930263 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  470  -  cost:  0.022206571  - MSE:  16.196406959990068 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  471  -  cost:  0.021419294  - MSE:  17.250492302049086 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  472  -  cost:  0.021257954  - MSE:  16.31212632775705 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  473  -  cost:  0.020562036  - MSE:  17.931105913727542 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  474  -  cost:  0.020392537  - MSE:  16.52914234704967 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  475  -  cost:  0.019370468  - MSE:  18.406950647687456 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  476  -  cost:  0.018604318  - MSE:  17.032305311028285 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  477  -  cost:  0.01762604  - MSE:  18.626672261958564 - Train Accuracy:  1.0\n",
      "Accuracy:  0.7936508\n",
      "epoch:  478  -  cost:  0.01689194  - MSE:  17.708244141134166 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  479  -  cost:  0.016234625  - MSE:  18.768309511478115 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  480  -  cost:  0.015749523  - MSE:  18.32028511079168 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  481  -  cost:  0.015273077  - MSE:  18.977114446503208 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  482  -  cost:  0.0149039645  - MSE:  18.81248287886515 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  483  -  cost:  0.014508043  - MSE:  19.286318460496382 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  484  -  cost:  0.014188306  - MSE:  19.172448873612876 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  485  -  cost:  0.013851966  - MSE:  19.612559164246832 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  486  -  cost:  0.013585618  - MSE:  19.41760024387425 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  487  -  cost:  0.013261262  - MSE:  19.932089885742236 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  488  -  cost:  0.012977411  - MSE:  19.786084421136746 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  489  -  cost:  0.012703783  - MSE:  20.226679977181938 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  490  -  cost:  0.012439971  - MSE:  20.043484600830432 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  491  -  cost:  0.012157304  - MSE:  20.52708082794854 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  492  -  cost:  0.011917219  - MSE:  20.319515964056627 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  493  -  cost:  0.01166242  - MSE:  20.807732709064243 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  494  -  cost:  0.011421734  - MSE:  20.68336359445469 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  495  -  cost:  0.01119213  - MSE:  21.030622075501654 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  496  -  cost:  0.011004709  - MSE:  20.935958852642745 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  497  -  cost:  0.0107833315  - MSE:  21.272063338424026 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  498  -  cost:  0.010629692  - MSE:  21.15856452067245 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  499  -  cost:  0.010401483  - MSE:  21.534698967620898 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  500  -  cost:  0.010218897  - MSE:  21.523848905071148 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  501  -  cost:  0.010013254  - MSE:  21.727236422883433 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  502  -  cost:  0.0098349955  - MSE:  21.754959871703733 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  503  -  cost:  0.0096504195  - MSE:  21.98550886443364 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  504  -  cost:  0.009475605  - MSE:  22.045400692539157 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  505  -  cost:  0.009315903  - MSE:  22.208919668348965 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  506  -  cost:  0.009155797  - MSE:  22.269627610728737 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  507  -  cost:  0.009019153  - MSE:  22.552198777732677 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  508  -  cost:  0.008865512  - MSE:  22.4498331498646 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  509  -  cost:  0.008734192  - MSE:  22.80650438435973 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  510  -  cost:  0.008606394  - MSE:  22.63504792706921 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  511  -  cost:  0.008464641  - MSE:  23.074536672707655 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  512  -  cost:  0.008320974  - MSE:  22.94301891652983 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  513  -  cost:  0.008185695  - MSE:  23.2269163690525 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  514  -  cost:  0.008055449  - MSE:  23.27826289031718 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  515  -  cost:  0.007922894  - MSE:  23.427430413618815 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  516  -  cost:  0.007817674  - MSE:  23.511361685488023 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  517  -  cost:  0.0076828618  - MSE:  23.69341003353453 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  518  -  cost:  0.0075756907  - MSE:  23.84603006029057 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  519  -  cost:  0.0074673244  - MSE:  23.882062411373692 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  520  -  cost:  0.0073651904  - MSE:  24.1282926177117 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  521  -  cost:  0.007277709  - MSE:  24.02669831357407 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  522  -  cost:  0.007169582  - MSE:  24.33890491008374 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  523  -  cost:  0.0070848623  - MSE:  24.25163208342013 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  524  -  cost:  0.0069824373  - MSE:  24.511213774129192 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  525  -  cost:  0.0069045713  - MSE:  24.482955517929273 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  526  -  cost:  0.0068106866  - MSE:  24.677861895151377 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  527  -  cost:  0.0067320615  - MSE:  24.682373743868492 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  528  -  cost:  0.0066533918  - MSE:  24.822162405837144 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  529  -  cost:  0.006576573  - MSE:  24.80046111639391 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  530  -  cost:  0.0065050116  - MSE:  25.031199725105676 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  531  -  cost:  0.0064183925  - MSE:  25.030058420683538 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  532  -  cost:  0.006359088  - MSE:  25.17042495843197 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  533  -  cost:  0.0062999316  - MSE:  25.09586285441886 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  534  -  cost:  0.0062114974  - MSE:  25.30597014486695 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  535  -  cost:  0.0061354637  - MSE:  25.352907366714867 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  536  -  cost:  0.006055442  - MSE:  25.510302000779223 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  537  -  cost:  0.0059788893  - MSE:  25.49978510543372 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  538  -  cost:  0.0059178863  - MSE:  25.677472881917648 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  539  -  cost:  0.00583946  - MSE:  25.668137035424174 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  540  -  cost:  0.005769685  - MSE:  25.771275430951864 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  541  -  cost:  0.005702649  - MSE:  25.854438668409042 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  542  -  cost:  0.0056389933  - MSE:  25.96253657049692 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  543  -  cost:  0.005583667  - MSE:  25.956276333344558 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  544  -  cost:  0.0055129025  - MSE:  26.115922228560393 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  545  -  cost:  0.0054535153  - MSE:  26.12557331879072 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  546  -  cost:  0.005403627  - MSE:  26.301698939773235 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  547  -  cost:  0.0053480333  - MSE:  26.289428094869113 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  548  -  cost:  0.0052857674  - MSE:  26.442221727539938 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  549  -  cost:  0.005234679  - MSE:  26.484233904689876 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  550  -  cost:  0.0051836236  - MSE:  26.59023571209419 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  551  -  cost:  0.005137502  - MSE:  26.633199141895602 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  552  -  cost:  0.005080988  - MSE:  26.781314603942857 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  553  -  cost:  0.005035959  - MSE:  26.817079729638923 - Train Accuracy:  1.0\n",
      "Accuracy:  0.8095238\n",
      "epoch:  554  -  cost:  0.0049855877  - MSE:  26.954293339046266 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  555  -  cost:  0.0049408707  - MSE:  27.035619776833684 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  556  -  cost:  0.0048943358  - MSE:  27.060102191100825 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  557  -  cost:  0.004846368  - MSE:  27.20811028010081 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  558  -  cost:  0.004807831  - MSE:  27.236489005607154 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  559  -  cost:  0.004759539  - MSE:  27.377736857222995 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  560  -  cost:  0.0047194  - MSE:  27.38697510521408 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  561  -  cost:  0.004675339  - MSE:  27.51816825601036 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  562  -  cost:  0.004633492  - MSE:  27.58223509782665 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  563  -  cost:  0.004588644  - MSE:  27.684669728351405 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  564  -  cost:  0.004544117  - MSE:  27.787208173569166 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  565  -  cost:  0.0045112316  - MSE:  27.78909464955203 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  566  -  cost:  0.0044638556  - MSE:  27.95410996395731 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  567  -  cost:  0.0044215717  - MSE:  28.01793709949661 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  568  -  cost:  0.00438383  - MSE:  28.102262991864794 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  569  -  cost:  0.0043459847  - MSE:  28.16850280615209 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  570  -  cost:  0.004306654  - MSE:  28.29983811204319 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  571  -  cost:  0.004271835  - MSE:  28.294124822103882 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  572  -  cost:  0.004236614  - MSE:  28.479748827527846 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  573  -  cost:  0.004202932  - MSE:  28.439347877044266 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  574  -  cost:  0.0041600135  - MSE:  28.614327183172886 - Train Accuracy:  1.0\n",
      "Accuracy:  0.82539684\n",
      "epoch:  575  -  cost:  0.0041246144  - MSE:  28.644626409327 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  576  -  cost:  0.004092129  - MSE:  28.74819566593383 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  577  -  cost:  0.004056701  - MSE:  28.79547109829028 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  578  -  cost:  0.0040243845  - MSE:  28.88601538235354 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  579  -  cost:  0.003989602  - MSE:  28.936834462008846 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  580  -  cost:  0.0039598243  - MSE:  29.069267913664184 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  581  -  cost:  0.003930438  - MSE:  29.03160265723376 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  582  -  cost:  0.003897189  - MSE:  29.192002977664757 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  583  -  cost:  0.0038681908  - MSE:  29.218177674324295 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  584  -  cost:  0.003838629  - MSE:  29.295181711291228 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  585  -  cost:  0.0038068315  - MSE:  29.3489894198948 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  586  -  cost:  0.0037805662  - MSE:  29.41074867380727 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  587  -  cost:  0.0037540065  - MSE:  29.479259679526052 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  588  -  cost:  0.003725222  - MSE:  29.590098879951967 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  589  -  cost:  0.0036985746  - MSE:  29.566986401904174 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  590  -  cost:  0.0036724722  - MSE:  29.713736794019784 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  591  -  cost:  0.0036443041  - MSE:  29.726909892238265 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  592  -  cost:  0.0036177225  - MSE:  29.826325215071112 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  593  -  cost:  0.0035906828  - MSE:  29.864262137141658 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  594  -  cost:  0.003566372  - MSE:  29.960931407270387 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  595  -  cost:  0.0035407867  - MSE:  29.987399841637693 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  596  -  cost:  0.0035143462  - MSE:  30.088404200109537 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  597  -  cost:  0.0034915188  - MSE:  30.101607452772594 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  598  -  cost:  0.0034647968  - MSE:  30.21567771044368 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  599  -  cost:  0.0034402749  - MSE:  30.271096866871815 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  600  -  cost:  0.0034186116  - MSE:  30.31422834733308 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  601  -  cost:  0.0033920177  - MSE:  30.387811989246554 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  602  -  cost:  0.0033717833  - MSE:  30.43665844277368 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  603  -  cost:  0.0033488749  - MSE:  30.451435026564734 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  604  -  cost:  0.0033246707  - MSE:  30.529872408848647 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  605  -  cost:  0.0033061951  - MSE:  30.560442050328692 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  606  -  cost:  0.003281151  - MSE:  30.636014145306273 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  607  -  cost:  0.003262544  - MSE:  30.702930803749897 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  608  -  cost:  0.003241651  - MSE:  30.69204571654043 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  609  -  cost:  0.0032175116  - MSE:  30.784882187883284 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  610  -  cost:  0.003199799  - MSE:  30.852694556732207 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  611  -  cost:  0.003178856  - MSE:  30.85025787532535 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  612  -  cost:  0.0031571547  - MSE:  30.937865673109027 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  613  -  cost:  0.003140058  - MSE:  30.954036573188677 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  614  -  cost:  0.0031175548  - MSE:  31.027124265463105 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  615  -  cost:  0.0030998169  - MSE:  31.08526479802074 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  616  -  cost:  0.0030807096  - MSE:  31.091029371573295 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  617  -  cost:  0.0030609155  - MSE:  31.17239513064978 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  618  -  cost:  0.0030426274  - MSE:  31.197008864155265 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  619  -  cost:  0.003024827  - MSE:  31.273999136691508 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  620  -  cost:  0.0030074476  - MSE:  31.28062350239282 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  621  -  cost:  0.0029867657  - MSE:  31.356288446547566 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  622  -  cost:  0.0029722543  - MSE:  31.423561803411715 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  623  -  cost:  0.0029535869  - MSE:  31.402737345138267 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  624  -  cost:  0.002934477  - MSE:  31.486061475821337 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  625  -  cost:  0.0029196728  - MSE:  31.51520397935184 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  626  -  cost:  0.0029006903  - MSE:  31.57989828537715 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  627  -  cost:  0.0028844615  - MSE:  31.625057417979225 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  628  -  cost:  0.002867746  - MSE:  31.65923095931667 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  629  -  cost:  0.0028509935  - MSE:  31.69185735604138 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  630  -  cost:  0.0028347117  - MSE:  31.761624620344588 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  631  -  cost:  0.002818198  - MSE:  31.78963433985284 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  632  -  cost:  0.002803492  - MSE:  31.825824055558417 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  633  -  cost:  0.002786628  - MSE:  31.88657596505356 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  634  -  cost:  0.0027714132  - MSE:  31.89329217024672 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  635  -  cost:  0.0027568713  - MSE:  31.95932449729868 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  636  -  cost:  0.0027405706  - MSE:  32.001256527150616 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  637  -  cost:  0.002726521  - MSE:  32.021382237087515 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  638  -  cost:  0.0027109866  - MSE:  32.09875634857446 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  639  -  cost:  0.002697304  - MSE:  32.09568573037733 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  640  -  cost:  0.0026820533  - MSE:  32.184220681594304 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  641  -  cost:  0.0026672548  - MSE:  32.17626800321924 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  642  -  cost:  0.0026545068  - MSE:  32.2719085255096 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  643  -  cost:  0.0026389179  - MSE:  32.26734467425 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  644  -  cost:  0.002625357  - MSE:  32.33704443314143 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  645  -  cost:  0.0026123524  - MSE:  32.31756828335962 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  646  -  cost:  0.0025959888  - MSE:  32.42506313022909 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  647  -  cost:  0.0025826637  - MSE:  32.448114829790136 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  648  -  cost:  0.0025696456  - MSE:  32.45562542988186 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  649  -  cost:  0.002555257  - MSE:  32.549134787556 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  650  -  cost:  0.002541867  - MSE:  32.56279715653249 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  651  -  cost:  0.0025280118  - MSE:  32.61700677000803 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  652  -  cost:  0.002516458  - MSE:  32.632585962469015 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  653  -  cost:  0.0025017778  - MSE:  32.69733499362102 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  654  -  cost:  0.00248928  - MSE:  32.73174079339675 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  655  -  cost:  0.002476857  - MSE:  32.76693112280174 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  656  -  cost:  0.0024635668  - MSE:  32.81517266142872 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  657  -  cost:  0.0024511768  - MSE:  32.86227410520269 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  658  -  cost:  0.0024385443  - MSE:  32.89918151968833 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  659  -  cost:  0.002427192  - MSE:  32.929389191702484 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  660  -  cost:  0.0024139625  - MSE:  32.976074285267075 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  661  -  cost:  0.0024028895  - MSE:  33.015316203258266 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  662  -  cost:  0.0023911027  - MSE:  33.03815119435807 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  663  -  cost:  0.0023787064  - MSE:  33.11766860375837 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  664  -  cost:  0.002368448  - MSE:  33.083352537241474 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  665  -  cost:  0.002354737  - MSE:  33.17434011976086 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  666  -  cost:  0.0023431918  - MSE:  33.198910829238734 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  667  -  cost:  0.0023313765  - MSE:  33.24745972085982 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  668  -  cost:  0.0023204428  - MSE:  33.28645659155027 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  669  -  cost:  0.002309465  - MSE:  33.30040619588927 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  670  -  cost:  0.0022970615  - MSE:  33.38401851779572 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  671  -  cost:  0.002286395  - MSE:  33.392035960120594 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  672  -  cost:  0.0022752462  - MSE:  33.47051208012128 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  673  -  cost:  0.0022646342  - MSE:  33.47548336731988 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  674  -  cost:  0.002252899  - MSE:  33.55226974347817 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  675  -  cost:  0.0022427957  - MSE:  33.53902833205512 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  676  -  cost:  0.002231749  - MSE:  33.62480565800031 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  677  -  cost:  0.0022206467  - MSE:  33.6282753393745 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  678  -  cost:  0.0022103542  - MSE:  33.696694271726635 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  679  -  cost:  0.0022008047  - MSE:  33.68415978817759 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  680  -  cost:  0.0021899876  - MSE:  33.776128913355855 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  681  -  cost:  0.0021794438  - MSE:  33.77839093713338 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  682  -  cost:  0.0021700503  - MSE:  33.85561392672605 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  683  -  cost:  0.002160696  - MSE:  33.83030758018849 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  684  -  cost:  0.0021491146  - MSE:  33.91768911175747 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  685  -  cost:  0.0021399686  - MSE:  33.92744034521439 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  686  -  cost:  0.0021301515  - MSE:  34.00553651415756 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  687  -  cost:  0.0021215256  - MSE:  33.987683744188544 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  688  -  cost:  0.0021103332  - MSE:  34.068681974330026 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  689  -  cost:  0.0021017008  - MSE:  34.0620082748459 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  690  -  cost:  0.0020920413  - MSE:  34.133855701063894 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  691  -  cost:  0.0020824887  - MSE:  34.15894108963554 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  692  -  cost:  0.002073586  - MSE:  34.19565667259185 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  693  -  cost:  0.002064305  - MSE:  34.25344417818617 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  694  -  cost:  0.0020565093  - MSE:  34.23770812664665 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  695  -  cost:  0.0020459557  - MSE:  34.31546611545888 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  696  -  cost:  0.0020375699  - MSE:  34.32852669421283 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  697  -  cost:  0.002028988  - MSE:  34.36740633397103 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  698  -  cost:  0.0020200375  - MSE:  34.432512876405866 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  699  -  cost:  0.0020116083  - MSE:  34.426009124370196 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  700  -  cost:  0.0020029913  - MSE:  34.50540954613703 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  701  -  cost:  0.0019949628  - MSE:  34.49044594839559 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  702  -  cost:  0.001985531  - MSE:  34.560568130504485 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  703  -  cost:  0.0019774956  - MSE:  34.57784075254091 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  704  -  cost:  0.0019696052  - MSE:  34.61196366946066 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  705  -  cost:  0.0019612198  - MSE:  34.66443147918428 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  706  -  cost:  0.0019532656  - MSE:  34.69215110583099 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  707  -  cost:  0.0019449049  - MSE:  34.73043261496362 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  708  -  cost:  0.0019375918  - MSE:  34.75301751247678 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  709  -  cost:  0.0019295104  - MSE:  34.78565543351893 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  710  -  cost:  0.0019215569  - MSE:  34.83281662928855 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  711  -  cost:  0.0019140653  - MSE:  34.86487118734129 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  712  -  cost:  0.0019062776  - MSE:  34.90647898007104 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  713  -  cost:  0.0018995582  - MSE:  34.90193095047456 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  714  -  cost:  0.0018909811  - MSE:  34.965615527784756 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  715  -  cost:  0.0018841767  - MSE:  35.00909289966029 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  716  -  cost:  0.0018770926  - MSE:  34.989775339871755 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  717  -  cost:  0.0018691232  - MSE:  35.059350097899284 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  718  -  cost:  0.0018621068  - MSE:  35.088397855055156 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  719  -  cost:  0.001854647  - MSE:  35.130826831236426 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  720  -  cost:  0.0018486734  - MSE:  35.112006486541716 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  721  -  cost:  0.0018402847  - MSE:  35.17706637820312 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  722  -  cost:  0.001834151  - MSE:  35.23088475042614 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  723  -  cost:  0.0018264923  - MSE:  35.22813399324714 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  724  -  cost:  0.0018200916  - MSE:  35.2908897759942 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  725  -  cost:  0.0018131328  - MSE:  35.288754083915656 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  726  -  cost:  0.0018060282  - MSE:  35.34519971737977 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  727  -  cost:  0.0017993009  - MSE:  35.37650518595717 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  728  -  cost:  0.0017927268  - MSE:  35.394470865930515 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  729  -  cost:  0.0017862809  - MSE:  35.42348328774854 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  730  -  cost:  0.0017796643  - MSE:  35.44341545888872 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  731  -  cost:  0.0017733449  - MSE:  35.49612164541134 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  732  -  cost:  0.0017664954  - MSE:  35.512809697576124 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  733  -  cost:  0.0017604567  - MSE:  35.54043793188387 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  734  -  cost:  0.0017538886  - MSE:  35.58845966716032 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  735  -  cost:  0.0017484033  - MSE:  35.58355908080166 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  736  -  cost:  0.0017411427  - MSE:  35.63957267552877 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  737  -  cost:  0.0017354473  - MSE:  35.659706247993974 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  738  -  cost:  0.0017289112  - MSE:  35.692480274591226 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  739  -  cost:  0.0017230108  - MSE:  35.72801112739544 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  740  -  cost:  0.0017169998  - MSE:  35.735359611611514 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  741  -  cost:  0.0017107546  - MSE:  35.7947217416152 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  742  -  cost:  0.0017049542  - MSE:  35.78858848593094 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  743  -  cost:  0.0016985565  - MSE:  35.846608460351426 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  744  -  cost:  0.0016927924  - MSE:  35.871581646652764 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  745  -  cost:  0.0016869908  - MSE:  35.90788296924762 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  746  -  cost:  0.0016817859  - MSE:  35.89752094231952 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  747  -  cost:  0.0016749994  - MSE:  35.95696141007833 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  748  -  cost:  0.0016695953  - MSE:  35.98304112947907 - Train Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84126985\n",
      "epoch:  749  -  cost:  0.0016637576  - MSE:  36.02572405515151 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  750  -  cost:  0.0016588492  - MSE:  36.00442626101893 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  751  -  cost:  0.0016522721  - MSE:  36.063463906635846 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  752  -  cost:  0.0016469352  - MSE:  36.106107026753456 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  753  -  cost:  0.0016412768  - MSE:  36.11146611268713 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  754  -  cost:  0.0016355988  - MSE:  36.15949459706721 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  755  -  cost:  0.0016305478  - MSE:  36.16222053959638 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  756  -  cost:  0.0016246005  - MSE:  36.21663292951006 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  757  -  cost:  0.001619265  - MSE:  36.225097622728235 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  758  -  cost:  0.0016137952  - MSE:  36.271986122633535 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  759  -  cost:  0.0016083154  - MSE:  36.279760130072034 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  760  -  cost:  0.0016032537  - MSE:  36.32706446423765 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  761  -  cost:  0.0015981087  - MSE:  36.31923811667359 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  762  -  cost:  0.0015925877  - MSE:  36.37435773228878 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  763  -  cost:  0.0015871718  - MSE:  36.39846784057465 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  764  -  cost:  0.0015823913  - MSE:  36.441450760477174 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  765  -  cost:  0.0015768926  - MSE:  36.43437632964996 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  766  -  cost:  0.0015720866  - MSE:  36.48502362077189 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  767  -  cost:  0.0015669693  - MSE:  36.488255224542335 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  768  -  cost:  0.0015617142  - MSE:  36.53963013979017 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  769  -  cost:  0.0015567289  - MSE:  36.54431533289171 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  770  -  cost:  0.001551668  - MSE:  36.59399163756714 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  771  -  cost:  0.0015466609  - MSE:  36.612896706515265 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  772  -  cost:  0.001541777  - MSE:  36.63765812021375 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  773  -  cost:  0.0015372011  - MSE:  36.644497797785185 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  774  -  cost:  0.0015319255  - MSE:  36.697035498383315 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  775  -  cost:  0.0015271732  - MSE:  36.70230088270378 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  776  -  cost:  0.0015223165  - MSE:  36.74558884214546 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  777  -  cost:  0.0015173415  - MSE:  36.770137074012794 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  778  -  cost:  0.0015130121  - MSE:  36.79845415510936 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  779  -  cost:  0.0015080903  - MSE:  36.81302516774574 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  780  -  cost:  0.0015035239  - MSE:  36.85211967729415 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  781  -  cost:  0.0014988112  - MSE:  36.854496607127764 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  782  -  cost:  0.0014943522  - MSE:  36.908463735485284 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  783  -  cost:  0.0014894846  - MSE:  36.9237119891001 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  784  -  cost:  0.0014851355  - MSE:  36.94541591470897 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  785  -  cost:  0.0014806675  - MSE:  36.96225010205495 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  786  -  cost:  0.0014761058  - MSE:  37.00595845139971 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  787  -  cost:  0.0014715019  - MSE:  37.01985370737074 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  788  -  cost:  0.0014672454  - MSE:  37.057950941969544 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  789  -  cost:  0.0014625351  - MSE:  37.065523787805596 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  790  -  cost:  0.0014584099  - MSE:  37.104098857452946 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  791  -  cost:  0.0014540437  - MSE:  37.10379913831876 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  792  -  cost:  0.0014495868  - MSE:  37.146983546596985 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  793  -  cost:  0.0014451699  - MSE:  37.17616084745406 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  794  -  cost:  0.0014410453  - MSE:  37.194233911452315 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  795  -  cost:  0.0014365042  - MSE:  37.220452751881204 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  796  -  cost:  0.0014329284  - MSE:  37.255777622413355 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  797  -  cost:  0.0014283214  - MSE:  37.248302827009894 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  798  -  cost:  0.0014239637  - MSE:  37.29794458519455 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  799  -  cost:  0.0014194903  - MSE:  37.31441290082177 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  800  -  cost:  0.0014155624  - MSE:  37.352740352120684 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  801  -  cost:  0.0014112302  - MSE:  37.34921796560372 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  802  -  cost:  0.0014072569  - MSE:  37.38997208421717 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  803  -  cost:  0.0014029408  - MSE:  37.398257651258625 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  804  -  cost:  0.0013990016  - MSE:  37.436488207589576 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  805  -  cost:  0.0013948302  - MSE:  37.43498483407706 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  806  -  cost:  0.001390703  - MSE:  37.48101132048387 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  807  -  cost:  0.0013864988  - MSE:  37.491060017698956 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  808  -  cost:  0.001382427  - MSE:  37.52022163345872 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  809  -  cost:  0.0013783546  - MSE:  37.50816655094516 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  810  -  cost:  0.0013739978  - MSE:  37.55801133826386 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  811  -  cost:  0.0013696189  - MSE:  37.56011355631109 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  812  -  cost:  0.0013655971  - MSE:  37.59342532242835 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  813  -  cost:  0.0013612886  - MSE:  37.599352881714196 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  814  -  cost:  0.0013573442  - MSE:  37.629502297642134 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  815  -  cost:  0.0013532614  - MSE:  37.62555641145281 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  816  -  cost:  0.0013491914  - MSE:  37.667737611464695 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  817  -  cost:  0.0013450556  - MSE:  37.6711091582441 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  818  -  cost:  0.0013411678  - MSE:  37.71748446696809 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  819  -  cost:  0.0013369613  - MSE:  37.7251264109851 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  820  -  cost:  0.0013330529  - MSE:  37.7442662653968 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  821  -  cost:  0.0013289526  - MSE:  37.75924185203504 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  822  -  cost:  0.0013253515  - MSE:  37.79462889391174 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  823  -  cost:  0.0013212884  - MSE:  37.79209007614155 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  824  -  cost:  0.001317373  - MSE:  37.81868168756513 - Train Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84126985\n",
      "epoch:  825  -  cost:  0.0013135843  - MSE:  37.83130459314449 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  826  -  cost:  0.0013096817  - MSE:  37.854290663059416 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  827  -  cost:  0.0013058113  - MSE:  37.88318615654364 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  828  -  cost:  0.0013021824  - MSE:  37.90388597576625 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  829  -  cost:  0.0012984467  - MSE:  37.90001112476618 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  830  -  cost:  0.0012946606  - MSE:  37.94671947587456 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  831  -  cost:  0.0012909179  - MSE:  37.95360092241692 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  832  -  cost:  0.0012870702  - MSE:  37.97359945293527 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  833  -  cost:  0.0012834538  - MSE:  37.98915229631792 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  834  -  cost:  0.0012797802  - MSE:  38.012284085302745 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  835  -  cost:  0.0012763637  - MSE:  38.013551526149016 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  836  -  cost:  0.0012724362  - MSE:  38.04945308928439 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  837  -  cost:  0.0012689435  - MSE:  38.063056804642386 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  838  -  cost:  0.0012653203  - MSE:  38.088404932830116 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  839  -  cost:  0.0012617066  - MSE:  38.106053370957866 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  840  -  cost:  0.0012583042  - MSE:  38.11669575990788 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  841  -  cost:  0.001254574  - MSE:  38.15219244485941 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  842  -  cost:  0.001251461  - MSE:  38.17068545507643 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  843  -  cost:  0.0012479718  - MSE:  38.15835551304539 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  844  -  cost:  0.0012442754  - MSE:  38.21054751118628 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  845  -  cost:  0.0012408277  - MSE:  38.22029862586195 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  846  -  cost:  0.0012373254  - MSE:  38.24304508692546 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  847  -  cost:  0.0012338342  - MSE:  38.273581553218186 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  848  -  cost:  0.0012305412  - MSE:  38.27908623221325 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  849  -  cost:  0.001227068  - MSE:  38.29703615732795 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  850  -  cost:  0.0012238597  - MSE:  38.30095312809343 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  851  -  cost:  0.0012204243  - MSE:  38.341582054455195 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  852  -  cost:  0.0012170757  - MSE:  38.359521437409384 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  853  -  cost:  0.0012136564  - MSE:  38.3735503260831 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  854  -  cost:  0.0012105262  - MSE:  38.397557666990885 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  855  -  cost:  0.001207087  - MSE:  38.40899904739829 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  856  -  cost:  0.001203924  - MSE:  38.41631325425546 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  857  -  cost:  0.0012006662  - MSE:  38.45289909369179 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  858  -  cost:  0.0011973605  - MSE:  38.46976515635269 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  859  -  cost:  0.0011941344  - MSE:  38.484410098440385 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  860  -  cost:  0.0011909598  - MSE:  38.50260816535207 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  861  -  cost:  0.0011877083  - MSE:  38.524286270399124 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  862  -  cost:  0.0011846622  - MSE:  38.54327717112835 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  863  -  cost:  0.0011815623  - MSE:  38.54599088080882 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  864  -  cost:  0.0011782697  - MSE:  38.57972775904211 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  865  -  cost:  0.0011753212  - MSE:  38.59155098073509 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  866  -  cost:  0.0011720703  - MSE:  38.6171888169567 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  867  -  cost:  0.0011691033  - MSE:  38.62771050861327 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  868  -  cost:  0.001165978  - MSE:  38.649975317264605 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  869  -  cost:  0.0011631352  - MSE:  38.65416365602393 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  870  -  cost:  0.0011597967  - MSE:  38.68044755249589 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  871  -  cost:  0.0011568703  - MSE:  38.69860009422406 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  872  -  cost:  0.0011538706  - MSE:  38.71749004739751 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  873  -  cost:  0.00115086  - MSE:  38.7342892385691 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  874  -  cost:  0.0011479437  - MSE:  38.75027921205141 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  875  -  cost:  0.001145058  - MSE:  38.75777510040256 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  876  -  cost:  0.0011419511  - MSE:  38.779114893118425 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  877  -  cost:  0.0011391412  - MSE:  38.80342457748524 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  878  -  cost:  0.0011361232  - MSE:  38.83003638744975 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  879  -  cost:  0.0011332324  - MSE:  38.829427922978844 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  880  -  cost:  0.0011302211  - MSE:  38.85215780090166 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  881  -  cost:  0.0011274524  - MSE:  38.87056273126148 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  882  -  cost:  0.0011245604  - MSE:  38.88086422038491 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  883  -  cost:  0.0011218482  - MSE:  38.89505625293919 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  884  -  cost:  0.0011188127  - MSE:  38.92259895244567 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  885  -  cost:  0.0011161166  - MSE:  38.93552649584164 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  886  -  cost:  0.0011131509  - MSE:  38.95515713177156 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  887  -  cost:  0.0011103372  - MSE:  38.9835938246843 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  888  -  cost:  0.0011073971  - MSE:  38.99398552368443 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  889  -  cost:  0.0011045267  - MSE:  39.015352974860576 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  890  -  cost:  0.0011017284  - MSE:  39.039658194119916 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  891  -  cost:  0.0010988871  - MSE:  39.040723807087915 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  892  -  cost:  0.0010960052  - MSE:  39.07703055416869 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  893  -  cost:  0.001093113  - MSE:  39.09450731827221 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  894  -  cost:  0.0010903045  - MSE:  39.10467924607593 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  895  -  cost:  0.0010876541  - MSE:  39.12998410981243 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  896  -  cost:  0.0010847665  - MSE:  39.12681978528138 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  897  -  cost:  0.0010821266  - MSE:  39.15493438788063 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  898  -  cost:  0.0010790916  - MSE:  39.167132431183624 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  899  -  cost:  0.001076586  - MSE:  39.191359920330996 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  900  -  cost:  0.0010737835  - MSE:  39.190356558734436 - Train Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84126985\n",
      "epoch:  901  -  cost:  0.0010711824  - MSE:  39.21868884647419 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  902  -  cost:  0.0010683486  - MSE:  39.229882928053044 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  903  -  cost:  0.001065658  - MSE:  39.24702481679926 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  904  -  cost:  0.0010631006  - MSE:  39.26340329652951 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  905  -  cost:  0.0010604492  - MSE:  39.2721372898012 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  906  -  cost:  0.0010577894  - MSE:  39.293511550676584 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  907  -  cost:  0.001055062  - MSE:  39.30312529737828 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  908  -  cost:  0.0010525956  - MSE:  39.3330502422924 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  909  -  cost:  0.0010497525  - MSE:  39.34034356584361 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  910  -  cost:  0.0010472969  - MSE:  39.3498122978662 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  911  -  cost:  0.0010445172  - MSE:  39.37512945069016 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  912  -  cost:  0.0010420473  - MSE:  39.37851546078525 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  913  -  cost:  0.0010391009  - MSE:  39.39943810101098 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  914  -  cost:  0.0010365976  - MSE:  39.41431370708661 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  915  -  cost:  0.0010339343  - MSE:  39.43869557636769 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  916  -  cost:  0.0010313959  - MSE:  39.446464560653084 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  917  -  cost:  0.0010286479  - MSE:  39.473873264363526 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  918  -  cost:  0.0010260897  - MSE:  39.485327159600146 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  919  -  cost:  0.0010236683  - MSE:  39.50097987737685 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  920  -  cost:  0.0010210595  - MSE:  39.50406203828103 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  921  -  cost:  0.0010183982  - MSE:  39.53484955290609 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  922  -  cost:  0.0010158415  - MSE:  39.54725119912781 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  923  -  cost:  0.0010133398  - MSE:  39.561448341605384 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  924  -  cost:  0.0010109012  - MSE:  39.57158536546116 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  925  -  cost:  0.0010082319  - MSE:  39.59116365443853 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  926  -  cost:  0.0010058755  - MSE:  39.61135272800353 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  927  -  cost:  0.0010033752  - MSE:  39.6146527448524 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  928  -  cost:  0.0010009547  - MSE:  39.64231917052585 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  929  -  cost:  0.0009983679  - MSE:  39.645205823371306 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  930  -  cost:  0.0009959951  - MSE:  39.666600125930096 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  931  -  cost:  0.0009936043  - MSE:  39.67689081897722 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  932  -  cost:  0.0009911249  - MSE:  39.696709071519194 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  933  -  cost:  0.0009887618  - MSE:  39.70912659931207 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  934  -  cost:  0.0009863846  - MSE:  39.73461654880255 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  935  -  cost:  0.0009842217  - MSE:  39.72903431604786 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  936  -  cost:  0.0009815403  - MSE:  39.75992659312948 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  937  -  cost:  0.000979344  - MSE:  39.76080228240478 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  938  -  cost:  0.000976949  - MSE:  39.788777070854394 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  939  -  cost:  0.0009748684  - MSE:  39.78462898812584 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  940  -  cost:  0.0009722494  - MSE:  39.8236757956304 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  941  -  cost:  0.00097008824  - MSE:  39.84112938665317 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  942  -  cost:  0.00096787047  - MSE:  39.83684966693324 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  943  -  cost:  0.0009654002  - MSE:  39.869828266333286 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  944  -  cost:  0.0009632828  - MSE:  39.87380747328583 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  945  -  cost:  0.0009608097  - MSE:  39.8965275771068 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  946  -  cost:  0.00095882197  - MSE:  39.91915569395209 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  947  -  cost:  0.0009565071  - MSE:  39.91439489172092 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  948  -  cost:  0.00095416914  - MSE:  39.95543487330415 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  949  -  cost:  0.00095197104  - MSE:  39.95446015147423 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  950  -  cost:  0.00094994926  - MSE:  39.987427943918334 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  951  -  cost:  0.00094769854  - MSE:  39.98048263214104 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  952  -  cost:  0.0009453158  - MSE:  40.012545507690525 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  953  -  cost:  0.00094321545  - MSE:  40.020644132824884 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  954  -  cost:  0.00094106846  - MSE:  40.02061946354286 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  955  -  cost:  0.0009386974  - MSE:  40.057903985616576 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  956  -  cost:  0.0009367342  - MSE:  40.05717885413732 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  957  -  cost:  0.0009344164  - MSE:  40.08495223898173 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  958  -  cost:  0.0009322303  - MSE:  40.08366215160615 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  959  -  cost:  0.000930236  - MSE:  40.11919896536348 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  960  -  cost:  0.00092812185  - MSE:  40.10865190112115 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  961  -  cost:  0.00092585426  - MSE:  40.149152247108034 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  962  -  cost:  0.00092382194  - MSE:  40.15029645650322 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  963  -  cost:  0.00092160475  - MSE:  40.17528415338027 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  964  -  cost:  0.00091960013  - MSE:  40.1855233879191 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  965  -  cost:  0.0009177472  - MSE:  40.17995165396893 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  966  -  cost:  0.00091541104  - MSE:  40.21847253807466 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  967  -  cost:  0.00091343187  - MSE:  40.23336165883053 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  968  -  cost:  0.00091158197  - MSE:  40.22500367418264 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  969  -  cost:  0.0009092759  - MSE:  40.26154592601362 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  970  -  cost:  0.000907281  - MSE:  40.27089876025654 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  971  -  cost:  0.00090522063  - MSE:  40.28979453841469 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  972  -  cost:  0.0009032928  - MSE:  40.28870987118851 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  973  -  cost:  0.00090122805  - MSE:  40.32827066931022 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  974  -  cost:  0.0008991261  - MSE:  40.32606572867477 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  975  -  cost:  0.0008970781  - MSE:  40.36435118899635 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  976  -  cost:  0.00089514453  - MSE:  40.35578150838237 - Train Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84126985\n",
      "epoch:  977  -  cost:  0.00089303486  - MSE:  40.39086191824872 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  978  -  cost:  0.0008909907  - MSE:  40.397552177192054 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  979  -  cost:  0.00088910037  - MSE:  40.40658951238724 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  980  -  cost:  0.00088703644  - MSE:  40.435886265540766 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  981  -  cost:  0.0008850002  - MSE:  40.442610231060094 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  982  -  cost:  0.0008831744  - MSE:  40.4658561689642 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  983  -  cost:  0.00088132237  - MSE:  40.46170081529919 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  984  -  cost:  0.000879204  - MSE:  40.49321709677508 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  985  -  cost:  0.0008772843  - MSE:  40.502500919727744 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  986  -  cost:  0.00087542046  - MSE:  40.52051390309179 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  987  -  cost:  0.00087354373  - MSE:  40.51872341621664 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  988  -  cost:  0.00087158196  - MSE:  40.55250138247373 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  989  -  cost:  0.0008697382  - MSE:  40.555601630138966 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  990  -  cost:  0.0008678029  - MSE:  40.57541797089022 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  991  -  cost:  0.0008659356  - MSE:  40.57691041090517 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  992  -  cost:  0.0008640964  - MSE:  40.60860348068787 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  993  -  cost:  0.0008622545  - MSE:  40.61244705713676 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  994  -  cost:  0.0008603684  - MSE:  40.63294607381366 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  995  -  cost:  0.0008586598  - MSE:  40.63191034303991 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  996  -  cost:  0.00085669686  - MSE:  40.66216347329963 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  997  -  cost:  0.00085481245  - MSE:  40.668783421308795 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  998  -  cost:  0.00085308484  - MSE:  40.67821052941499 - Train Accuracy:  1.0\n",
      "Accuracy:  0.84126985\n",
      "epoch:  999  -  cost:  0.000851257  - MSE:  40.6975591905499 - Train Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "mse_history = []\n",
    "accuracy_history = []\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x:X_train, y_:Y_train})\n",
    "    cost = sess.run(cost_function, feed_dict={x:X_train, y_:Y_train})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x:x_test, y_:y_test})))\n",
    "    pred_y = sess.run(y, feed_dict={x:x_test} )\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - y_test))\n",
    "    mse_ = sess.run(mse)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x:X_train, y_:Y_train}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    print('epoch: ', epoch,' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %s C:\\Users\\Lenovo\\jupyter project\\rock and mines\n"
     ]
    }
   ],
   "source": [
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot mse and accuracy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mse_history, \"r\")\n",
    "plt.show()\n",
    "plt.plot(accuracy_history, \"r\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.84126985\n"
     ]
    }
   ],
   "source": [
    "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict={x:x_test, y_:y_test} )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the final mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 40.6976\n"
     ]
    }
   ],
   "source": [
    "pred_y = sess.run(y, feed_dict={x:x_test})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - y_test))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
